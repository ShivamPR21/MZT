digraph {
	graph [size="28.65,28.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140146209559152 [label="
 (5, 992, 30)" fillcolor=darkolivegreen1]
	140146142049712 [label=CatBackward0]
	140146142049856 -> 140146142049712
	140146142049856 [label=MaxBackward0]
	140146142050000 -> 140146142049856
	140146142050000 [label=EluBackward0]
	140146142050096 -> 140146142050000
	140146142050096 [label=ConvolutionBackward0]
	140146142050192 -> 140146142050096
	140146209583568 [label="layers.0.conv.0.weight
 (32, 6, 1, 1)" fillcolor=lightblue]
	140146209583568 -> 140146142050192
	140146142050192 [label=AccumulateGrad]
	140146142050144 -> 140146142050096
	140146209583648 [label="layers.0.conv.0.bias
 (32)" fillcolor=lightblue]
	140146209583648 -> 140146142050144
	140146142050144 [label=AccumulateGrad]
	140146142049808 -> 140146142049712
	140146142049808 [label=MaxBackward0]
	140146142049904 -> 140146142049808
	140146142049904 [label=EluBackward0]
	140146142050288 -> 140146142049904
	140146142050288 [label=ConvolutionBackward0]
	140146142050384 -> 140146142050288
	140146142050384 [label=CloneBackward0]
	140146142050576 -> 140146142050384
	140146142050576 [label=PermuteBackward0]
	140146142050672 -> 140146142050576
	140146142050672 [label=CatBackward0]
	140146142050768 -> 140146142050672
	140146142050768 [label=SubBackward0]
	140146142050912 -> 140146142050768
	140146142050912 [label=ViewBackward0]
	140146142051008 -> 140146142050912
	140146142051008 [label=IndexBackward0]
	140146142051104 -> 140146142051008
	140146142051104 [label=SliceBackward0]
	140146142051200 -> 140146142051104
	140146142051200 [label=ViewBackward0]
	140146142051296 -> 140146142051200
	140146142051296 [label=CloneBackward0]
	140146142051344 -> 140146142051296
	140146142051344 [label=TransposeBackward0]
	140146142049856 -> 140146142051344
	140146142050720 -> 140146142050768
	140146142050720 [label=RepeatBackward0]
	140146142051152 -> 140146142050720
	140146142051152 [label=ViewBackward0]
	140146142051344 -> 140146142051152
	140146142050720 -> 140146142050672
	140146142050336 -> 140146142050288
	140146209583808 [label="layers.1.conv.0.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140146209583808 -> 140146142050336
	140146142050336 [label=AccumulateGrad]
	140146142049952 -> 140146142050288
	140146209583888 [label="layers.1.conv.0.bias
 (64)" fillcolor=lightblue]
	140146209583888 -> 140146142049952
	140146142049952 [label=AccumulateGrad]
	140146142049664 -> 140146142049712
	140146142049664 [label=MaxBackward0]
	140146142050432 -> 140146142049664
	140146142050432 [label=EluBackward0]
	140146142050624 -> 140146142050432
	140146142050624 [label=NativeBatchNormBackward0]
	140146142050864 -> 140146142050624
	140146142050864 [label=ConvolutionBackward0]
	140146142050960 -> 140146142050864
	140146142050960 [label=CloneBackward0]
	140146142051488 -> 140146142050960
	140146142051488 [label=PermuteBackward0]
	140146142051584 -> 140146142051488
	140146142051584 [label=CatBackward0]
	140146142051680 -> 140146142051584
	140146142051680 [label=SubBackward0]
	140146142051824 -> 140146142051680
	140146142051824 [label=ViewBackward0]
	140146142051968 -> 140146142051824
	140146142051968 [label=IndexBackward0]
	140146142052016 -> 140146142051968
	140146142052016 [label=SliceBackward0]
	140146142052112 -> 140146142052016
	140146142052112 [label=ViewBackward0]
	140146142052208 -> 140146142052112
	140146142052208 [label=CloneBackward0]
	140146142052304 -> 140146142052208
	140146142052304 [label=TransposeBackward0]
	140146142049808 -> 140146142052304
	140146142051632 -> 140146142051680
	140146142051632 [label=RepeatBackward0]
	140146142052064 -> 140146142051632
	140146142052064 [label=ViewBackward0]
	140146142052304 -> 140146142052064
	140146142051632 -> 140146142051584
	140146142051248 -> 140146142050864
	140146209584048 [label="layers.2.conv.0.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	140146209584048 -> 140146142051248
	140146142051248 [label=AccumulateGrad]
	140146142049760 -> 140146142050864
	140146209584128 [label="layers.2.conv.0.bias
 (128)" fillcolor=lightblue]
	140146209584128 -> 140146142049760
	140146142049760 [label=AccumulateGrad]
	140146142050480 -> 140146142050624
	140150156484832 [label="layers.2.conv.1.weight
 (128)" fillcolor=lightblue]
	140150156484832 -> 140146142050480
	140146142050480 [label=AccumulateGrad]
	140146142050048 -> 140146142050624
	140150156068240 [label="layers.2.conv.1.bias
 (128)" fillcolor=lightblue]
	140150156068240 -> 140146142050048
	140146142050048 [label=AccumulateGrad]
	140146142049472 -> 140146142049712
	140146142049472 [label=MaxBackward0]
	140146142051056 -> 140146142049472
	140146142051056 [label=EluBackward0]
	140146142050816 -> 140146142051056
	140146142050816 [label=ConvolutionBackward0]
	140146142051392 -> 140146142050816
	140146142051392 [label=CloneBackward0]
	140146142052160 -> 140146142051392
	140146142052160 [label=PermuteBackward0]
	140146142051728 -> 140146142052160
	140146142051728 [label=CatBackward0]
	140146142051920 -> 140146142051728
	140146142051920 [label=SubBackward0]
	140146142081280 -> 140146142051920
	140146142081280 [label=ViewBackward0]
	140146142081376 -> 140146142081280
	140146142081376 [label=IndexBackward0]
	140146142081472 -> 140146142081376
	140146142081472 [label=SliceBackward0]
	140146142081568 -> 140146142081472
	140146142081568 [label=ViewBackward0]
	140146142081664 -> 140146142081568
	140146142081664 [label=CloneBackward0]
	140146142081760 -> 140146142081664
	140146142081760 [label=TransposeBackward0]
	140146142049664 -> 140146142081760
	140146142081136 -> 140146142051920
	140146142081136 [label=RepeatBackward0]
	140146142081520 -> 140146142081136
	140146142081520 [label=ViewBackward0]
	140146142081760 -> 140146142081520
	140146142081136 -> 140146142051728
	140146142051536 -> 140146142050816
	140146209584608 [label="layers.3.conv.0.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	140146209584608 -> 140146142051536
	140146142051536 [label=AccumulateGrad]
	140146142050240 -> 140146142050816
	140146209584688 [label="layers.3.conv.0.bias
 (256)" fillcolor=lightblue]
	140146209584688 -> 140146142050240
	140146142050240 [label=AccumulateGrad]
	140146142049616 -> 140146142049712
	140146142049616 [label=MaxBackward0]
	140146142051776 -> 140146142049616
	140146142051776 [label=EluBackward0]
	140146142051872 -> 140146142051776
	140146142051872 [label=ConvolutionBackward0]
	140146142050528 -> 140146142051872
	140146142050528 [label=CloneBackward0]
	140146142081328 -> 140146142050528
	140146142081328 [label=PermuteBackward0]
	140146142081808 -> 140146142081328
	140146142081808 [label=CatBackward0]
	140146142081904 -> 140146142081808
	140146142081904 [label=SubBackward0]
	140146142082048 -> 140146142081904
	140146142082048 [label=ViewBackward0]
	140146142082144 -> 140146142082048
	140146142082144 [label=IndexBackward0]
	140146142082240 -> 140146142082144
	140146142082240 [label=SliceBackward0]
	140146142082336 -> 140146142082240
	140146142082336 [label=ViewBackward0]
	140146142082432 -> 140146142082336
	140146142082432 [label=CloneBackward0]
	140146142082528 -> 140146142082432
	140146142082528 [label=TransposeBackward0]
	140146142049472 -> 140146142082528
	140146142081184 -> 140146142081904
	140146142081184 [label=RepeatBackward0]
	140146142082288 -> 140146142081184
	140146142082288 [label=ViewBackward0]
	140146142082528 -> 140146142082288
	140146142081184 -> 140146142081808
	140146142081232 -> 140146142051872
	140146209584848 [label="layers.4.conv.0.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	140146209584848 -> 140146142081232
	140146142081232 [label=AccumulateGrad]
	140146142081088 -> 140146142051872
	140146209584928 [label="layers.4.conv.0.bias
 (512)" fillcolor=lightblue]
	140146209584928 -> 140146142081088
	140146142081088 [label=AccumulateGrad]
	140146142049712 -> 140146209559152
}
